name: Local Config
version: 1.0.0
schema: v1
models:
  - name: llama3-8B
    provider: ollama
    model: llama3:8b
    roles:
      - chat
      - edit
      - apply
    parameters:
      temperature: 0.7
      max_tokens: 8192
  - name: GPT-4o
    provider: openai
    model: gpt-4o
    api_key: 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
    roles:
      - chat
      - edit
      - apply
    parameters:
      temperature: 0.5
      max_tokens: 4096
  - name: GPT-5
    provider: openai
    model: gpt-5
    api_key: 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
    roles:
      - chat
      - edit
      - apply
    parameters:
      temperature: 0.4
      max_tokens: 8192
  - name: Gemini Pro
    provider: google
    model: gemini-pro
    api_key: AIzaSyC94GOCGh3TrHmG1_PeQE1-nQ-ICaiwEnU
    roles:
      - chat
      - edit
      - apply
    parameters:
      temperature: 0.5
      max_tokens: 4096
